{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "34122a5b-9144-43f7-a1d6-e0d09334df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read original data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "Dataset_dir = \"C:/Users/0stix/Datasets/bike_sharing_demand/\"\n",
    "\n",
    "df_orig_train = pd.read_csv(Dataset_dir+\"train.csv\")\n",
    "df_orig_test = pd.read_csv(Dataset_dir+\"test.csv\")\n",
    "df_orig_sample = pd.read_csv(Dataset_dir+\"sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aa69b2ed-1b3c-4a93-a990-d12a4cdd0e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_orig_train.drop([\"casual\", \"registered\", \"count\"], axis=1).copy()\n",
    "y = df_orig_train[\"count\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "61456e3b-10bf-4ab6-b373-d131a66428a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "def rmsle(y, pred):\n",
    "    log_y = np.log1p(y)\n",
    "    log_pred = np.log1p(pred)\n",
    "    squared_error = (log_y - log_pred) ** 2\n",
    "    rmsle = np.sqrt(np.mean(squared_error))\n",
    "    return rmsle\n",
    "\n",
    "\n",
    "def rmse(y, pred):\n",
    "    return np.sqrt(mean_squared_error(y, pred))\n",
    "\n",
    "\n",
    "def evaluate_regr(y, pred):\n",
    "    dct_ = {'rmsle_val': rmsle(y, pred),\n",
    "            'rmse_val': rmse(y, pred),\n",
    "            'mae_val': mean_absolute_error(y, pred)}\n",
    "    print(dct_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "06b65784-53c7-4ef0-911b-a7cb85cc3298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "lin_attrib = ['temp','atemp','humidity','windspeed']\n",
    "cat_attrib = list(set(X)-set(lin_attrib)-set(['datetime']))\n",
    "\n",
    "class DataFrameEditor(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        df_copy = X.copy()\n",
    "        df_copy['datetime'] = df_copy.apply(pd.to_datetime)\n",
    "        df_copy['year'] = df_copy.datetime.apply(lambda x: x.year)\n",
    "        df_copy['month'] = df_copy.datetime.apply(lambda x: x.month)\n",
    "        df_copy['day'] = df_copy.datetime.apply(lambda x: x.day)\n",
    "        df_copy['hour'] = df_copy.datetime.apply(lambda x: x.hour)\n",
    "        df_copy.drop('datetime', axis=1, inplace=True)\n",
    "        return df_copy\n",
    "\n",
    "class DataFrameSelector(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6c57c525-9f0a-466b-82b0-3846d251fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(lin_attrib)),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(cat_attrib)),\n",
    "    ('1hot_encoder', OneHotEncoder(sparse=False))\n",
    "])\n",
    "\n",
    "\n",
    "nd_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('lin_pl', lin_pipeline),\n",
    "    ('cat_pl', cat_pipeline)\n",
    "])\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('df_edt',DataFrameEditor()),\n",
    "    ('bd_pl',nd_pipeline)\n",
    "])\n",
    "\n",
    "\n",
    "X = full_pipeline.fit_transform(X)\n",
    "y_log = np.log1p(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c24b2b91-f3c4-466a-ac42-40b5dc4fd001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_reg\n",
      "dict_items([('rmsle_val', 1.1743201485317574), ('rmse_val', 156.77034122473484), ('mae_val', 105.19221785243879)])\n",
      "gbm_reg\n",
      "dict_items([('rmsle_val', 1.1663981997256434), ('rmse_val', 159.2440777245701), ('mae_val', 107.10088597124299)])\n",
      "xgb_reg\n",
      "dict_items([('rmsle_val', 1.2379208888786128), ('rmse_val', 174.34446509629805), ('mae_val', 117.27102496918914)])\n",
      "lgbm_reg\n",
      "dict_items([('rmsle_val', 1.1656034728744467), ('rmse_val', 156.29860146654372), ('mae_val', 105.40760586564821)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "dct_model = {\n",
    "    'rf_reg':RandomForestRegressor(n_estimators=500),\n",
    "    'gbm_reg':GradientBoostingRegressor(n_estimators=500),\n",
    "    'xgb_reg':XGBRegressor(n_estimators=500),\n",
    "    'lgbm_reg':LGBMRegressor(n_estimators=500)\n",
    "}\n",
    "\n",
    "for name_, model_ in dct_model.items():\n",
    "    print(name_)\n",
    "    X_train, X_val, y_train_log, y_val_log = train_test_split(X, y_log, test_size=0.3, random_state=0)\n",
    "    model_.fit(X_train, y_train_log)\n",
    "    y_pred_log = model_.predict(X_val)\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    y_val = np.expm1(y_val_log)\n",
    "    evaluate_regr(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "69f324bf-376b-4599-af1a-7d791a286276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.22841418, -1.45029236, -0.30588308,  1.61722711,  1.        ,\n",
       "        0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = full_pipeline.transform(df_orig_test)\n",
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0c4e2040-e914-4dde-be05-9dc47668b809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6493, 16)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a7f97c23-fdac-4262-803d-f1cfe2611b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.250460827743694"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_log = dct_model['lgbm_reg'].predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fb3bee07-88e2-40c5-b539-8d31c81899ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame()\n",
    "df_submission['datetime'] = df_orig_test['datetime']\n",
    "df_submission['count'] = y_pred\n",
    "df_submission.set_index('datetime',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "62a6f70b-640a-4a00-9015-1238d2be49c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99cb24da-32b4-4f76-97a8-668fb8caac10",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e6a65fb57ed3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_orig_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"casual\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"registered\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"count\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_orig_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"count\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0my_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mX_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"datetime\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_' is not defined"
     ]
    }
   ],
   "source": [
    "class DataFrameSelector(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "    \n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "X = df_orig_train.drop([\"casual\", \"registered\", \"count\"], axis=1).copy()\n",
    "y = df_orig_train[\"count\"].copy()\n",
    "y_log = np.log1p(y_)\n",
    "\n",
    "X_[\"datetime\"] = X_.apply(pd.to_datetime)\n",
    "X_.drop(\"datetime\", axis=1, inplace=True)\n",
    "X_ = pd.get_dummies(X_, columns=[\"year\", \"month\", \"day\", \"hour\", \"holiday\", \"workingday\", \"season\", \"weather\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224f0def-aa59-4dd4-b219-76ec4f2a7d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "X_train, X_val, y_train_log, y_val_log = train_test_split(X_, y_log, test_size=0.3, random_state=0)\n",
    "\n",
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(X_train, y_train_log)\n",
    "y_pred_log = lr_reg.predict(X_val)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_val = np.expm1(y_val_log)\n",
    "evaluate_regr(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c81520b-33bc-429d-b090-8debf48e3576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "def rmsle(y, pred):\n",
    "    log_y = np.log1p(y)\n",
    "    log_pred = np.log1p(pred)\n",
    "    squared_error = (log_y - log_pred) ** 2\n",
    "    rmsle = np.sqrt(np.mean(squared_error))\n",
    "    return rmsle\n",
    "\n",
    "\n",
    "def rmse(y, pred):\n",
    "    return np.sqrt(mean_squared_error(y, pred))\n",
    "\n",
    "\n",
    "def evaluate_regr(y, pred):\n",
    "    dct_ = {'rmsle_val': rmsle(y, pred),\n",
    "            'rmse_val': rmse(y, pred),\n",
    "            'mae_val': mean_absolute_error(y, pred)}\n",
    "    print(dct_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6771e80-e8de-4c82-9a92-a9e0313fabd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
