{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read original data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "Dataset_dir = \"C:/Users/0stix/Datasets/bike_sharing_demand/\"\n",
    "\n",
    "df_orig_train = pd.read_csv(Dataset_dir+\"train.csv\")\n",
    "df_orig_test = pd.read_csv(Dataset_dir+\"test.csv\")\n",
    "df_orig_sample = pd.read_csv(Dataset_dir+\"sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "def rmsle(y, pred):\n",
    "    log_y = np.log1p(y)\n",
    "    log_pred = np.log1p(pred)\n",
    "    squared_error = (log_y - log_pred) ** 2\n",
    "    rmsle = np.sqrt(np.mean(squared_error))\n",
    "    return rmsle\n",
    "\n",
    "\n",
    "def rmse(y, pred):\n",
    "    return np.sqrt(mean_squared_error(y, pred))\n",
    "\n",
    "\n",
    "def evaluate_regr(y, pred):\n",
    "    dct_ = {'rmsle_val': rmsle(y, pred),\n",
    "            'rmse_val': rmse(y, pred),\n",
    "            'mae_val': mean_absolute_error(y, pred)}\n",
    "    print(dct_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_ = df_orig_train.drop([\"casual\", \"registered\", \"count\"], axis=1).copy()\n",
    "y_ = df_orig_train[\"count\"].copy()\n",
    "y_log = np.log1p(y_)\n",
    "\n",
    "X_[\"datetime\"] = X_.apply(pd.to_datetime)\n",
    "X_[\"year\"] = X_.datetime.apply(lambda x: x.year)\n",
    "X_[\"month\"] = X_.datetime.apply(lambda x: x.month)\n",
    "X_[\"day\"] = X_.datetime.apply(lambda x: x.day)\n",
    "X_[\"hour\"] = X_.datetime.apply(lambda x: x.hour)\n",
    "X_.drop(\"datetime\", axis=1, inplace=True)\n",
    "X_ = pd.get_dummies(X_, columns=[\"year\", \"month\", \"day\", \"hour\", \"holiday\", \"workingday\", \"season\", \"weather\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('rmsle_val', 0.5896341440364988), ('rmse_val', 97.68751161267781), ('mae_val', 63.381932073855516)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "X_train, X_val, y_train_log, y_val_log = train_test_split(X_, y_log, test_size=0.3, random_state=0)\n",
    "\n",
    "lr_reg = LinearRegression()\n",
    "lr_reg.fit(X_train, y_train_log)\n",
    "y_pred_log = lr_reg.predict(X_val)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_val = np.expm1(y_val_log)\n",
    "evaluate_regr(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call (<ipython-input-12-2a32a0ace43b>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-2a32a0ace43b>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    rf_reg.eval('n_estimator')=500\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to function call\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_reg = RandomForestRegressor()\n",
    "if 'n_estimator' in rf_reg.__getstate__():\n",
    "    eval\n",
    "    rf_reg.\n",
    "    rf_reg.eval('n_estimator')=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_reg\n",
      "dict_items([('rmsle_val', 0.3542084353353085), ('rmse_val', 50.188325658878306), ('mae_val', 31.126700904301927)])\n",
      "gbm_reg\n",
      "dict_items([('rmsle_val', 0.3298584393951831), ('rmse_val', 53.345227463761404), ('mae_val', 32.746364454822064)])\n",
      "xgb_reg\n",
      "dict_items([('rmsle_val', 0.3422048283339225), ('rmse_val', 51.73158151916774), ('mae_val', 31.251221714159207)])\n",
      "lgbm_reg\n",
      "dict_items([('rmsle_val', 0.3188456499157367), ('rmse_val', 47.21464677592674), ('mae_val', 29.028770412428237)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "dct_model = {\n",
    "    'rf_reg':RandomForestRegressor(n_estimators=500),\n",
    "    'gbm_reg':GradientBoostingRegressor(n_estimators=500),\n",
    "    'xgb_reg':XGBRegressor(n_estimators=500),\n",
    "    'lgbm_reg':LGBMRegressor(n_estimators=500)\n",
    "}\n",
    "\n",
    "for name_, model_ in dct_model.items():\n",
    "    print(name_)\n",
    "    X_train, X_val, y_train_log, y_val_log = train_test_split(X_, y_log, test_size=0.3, random_state=0)\n",
    "    model_.fit(X_train, y_train_log)\n",
    "    y_pred_log = model_.predict(X_val)\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    y_val = np.expm1(y_val_log)\n",
    "    evaluate_regr(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'2*n_jobs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0merror_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Evaluate a score by cross-validation\n",
       "\n",
       "Read more in the :ref:`User Guide <cross_validation>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "estimator : estimator object implementing 'fit'\n",
       "    The object to use to fit the data.\n",
       "\n",
       "X : array-like of shape (n_samples, n_features)\n",
       "    The data to fit. Can be for example a list, or an array.\n",
       "\n",
       "y : array-like of shape (n_samples,) or (n_samples, n_outputs),             default=None\n",
       "    The target variable to try to predict in the case of\n",
       "    supervised learning.\n",
       "\n",
       "groups : array-like of shape (n_samples,), default=None\n",
       "    Group labels for the samples used while splitting the dataset into\n",
       "    train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
       "    instance (e.g., :class:`GroupKFold`).\n",
       "\n",
       "scoring : str or callable, default=None\n",
       "    A str (see model evaluation documentation) or\n",
       "    a scorer callable object / function with signature\n",
       "    ``scorer(estimator, X, y)`` which should return only\n",
       "    a single value.\n",
       "\n",
       "    Similar to :func:`cross_validate`\n",
       "    but only a single metric is permitted.\n",
       "\n",
       "    If None, the estimator's default scorer (if available) is used.\n",
       "\n",
       "cv : int, cross-validation generator or an iterable, default=None\n",
       "    Determines the cross-validation splitting strategy.\n",
       "    Possible inputs for cv are:\n",
       "\n",
       "    - None, to use the default 5-fold cross validation,\n",
       "    - int, to specify the number of folds in a `(Stratified)KFold`,\n",
       "    - :term:`CV splitter`,\n",
       "    - An iterable yielding (train, test) splits as arrays of indices.\n",
       "\n",
       "    For int/None inputs, if the estimator is a classifier and ``y`` is\n",
       "    either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
       "    other cases, :class:`KFold` is used. These splitters are instantiated\n",
       "    with `shuffle=False` so the splits will be the same across calls.\n",
       "\n",
       "    Refer :ref:`User Guide <cross_validation>` for the various\n",
       "    cross-validation strategies that can be used here.\n",
       "\n",
       "    .. versionchanged:: 0.22\n",
       "        ``cv`` default value if None changed from 3-fold to 5-fold.\n",
       "\n",
       "n_jobs : int, default=None\n",
       "    Number of jobs to run in parallel. Training the estimator and computing\n",
       "    the score are parallelized over the cross-validation splits.\n",
       "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
       "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
       "    for more details.\n",
       "\n",
       "verbose : int, default=0\n",
       "    The verbosity level.\n",
       "\n",
       "fit_params : dict, default=None\n",
       "    Parameters to pass to the fit method of the estimator.\n",
       "\n",
       "pre_dispatch : int or str, default='2*n_jobs'\n",
       "    Controls the number of jobs that get dispatched during parallel\n",
       "    execution. Reducing this number can be useful to avoid an\n",
       "    explosion of memory consumption when more jobs get dispatched\n",
       "    than CPUs can process. This parameter can be:\n",
       "\n",
       "        - None, in which case all the jobs are immediately\n",
       "          created and spawned. Use this for lightweight and\n",
       "          fast-running jobs, to avoid delays due to on-demand\n",
       "          spawning of the jobs\n",
       "\n",
       "        - An int, giving the exact number of total jobs that are\n",
       "          spawned\n",
       "\n",
       "        - A str, giving an expression as a function of n_jobs,\n",
       "          as in '2*n_jobs'\n",
       "\n",
       "error_score : 'raise' or numeric, default=np.nan\n",
       "    Value to assign to the score if an error occurs in estimator fitting.\n",
       "    If set to 'raise', the error is raised.\n",
       "    If a numeric value is given, FitFailedWarning is raised.\n",
       "\n",
       "    .. versionadded:: 0.20\n",
       "\n",
       "Returns\n",
       "-------\n",
       "scores : ndarray of float of shape=(len(list(cv)),)\n",
       "    Array of scores of the estimator for each run of the cross validation.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn import datasets, linear_model\n",
       ">>> from sklearn.model_selection import cross_val_score\n",
       ">>> diabetes = datasets.load_diabetes()\n",
       ">>> X = diabetes.data[:150]\n",
       ">>> y = diabetes.target[:150]\n",
       ">>> lasso = linear_model.Lasso()\n",
       ">>> print(cross_val_score(lasso, X, y, cv=3))\n",
       "[0.33150734 0.08022311 0.03531764]\n",
       "\n",
       "See Also\n",
       "---------\n",
       "cross_validate : To run cross-validation on multiple metrics and also to\n",
       "    return train scores, fit times and score times.\n",
       "\n",
       "cross_val_predict : Get predictions from each split of cross-validation for\n",
       "    diagnostic purposes.\n",
       "\n",
       "sklearn.metrics.make_scorer : Make a scorer from a performance metric or\n",
       "    loss function.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\0stix\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "dct_pipeline = dict()\n",
    "\n",
    "for pipeline_ in dct_pipeline:\n",
    "    \n",
    "\n",
    "cross_val_score?\n",
    "\n",
    "# for model_name, model_ in dct_model:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
